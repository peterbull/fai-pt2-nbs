# AUTOGENERATED! DO NOT EDIT! File to edit: ../../02.01_pb_k_means.ipynb.

# %% auto 0
__all__ = ['n_clusters', 'n_samples', 'centroids', 'slices', 'data', 'sample', 'euclidean_dist', 'assign_to_nearest_centroid',
           'update_centroids', 'k_means', 'k_means_gpu']

# %% ../../02.01_pb_k_means.ipynb 3
import math, matplotlib.pyplot as plt, operator, torch
from functools import partial

from torch.distributions.multivariate_normal import MultivariateNormal
from torch import tensor

# %% ../../02.01_pb_k_means.ipynb 5
n_clusters = 5
n_samples = 200

# %% ../../02.01_pb_k_means.ipynb 7
centroids = torch.rand(n_clusters, 2)*70-35

# %% ../../02.01_pb_k_means.ipynb 9
def sample(m):
    return MultivariateNormal(m, torch.diag(tensor([5., 5.]))).sample((n_samples,))

# %% ../../02.01_pb_k_means.ipynb 10
slices = [sample(c) for c in centroids]
data = torch.cat(slices)

# %% ../../02.01_pb_k_means.ipynb 21
def euclidean_dist(a, b):
    return torch.norm(a-b, dim=-1)

# %% ../../02.01_pb_k_means.ipynb 30
def assign_to_nearest_centroid(data, centroids):
    distances = euclidean_dist(data.unsqueeze(1), centroids.unsqueeze(0))
    cluster_assignments = torch.argmin(distances, dim=1)
    return cluster_assignments

# %% ../../02.01_pb_k_means.ipynb 36
def update_centroids(data, cluster_assignments, n_clusters):
    updated_centroids = torch.zeros(n_clusters, data.shape[-1])
    for i in range(n_clusters):
        assigned_points = data[cluster_assignments == i]
        if len(assigned_points) > 0:
            updated_centroids[i] = torch.mean(assigned_points, dim=0)
    return updated_centroids

# %% ../../02.01_pb_k_means.ipynb 38
def k_means(data, n_clusters=5, max_iterations=10, tolerance=1e-4, centroids=None):
    converged = False

    for iteration in range(max_iterations):
        # assign data points to nearest centroid
        cluster_assignments = assign_to_nearest_centroid(data, centroids)
        # update centroids
        updated_centroids = update_centroids(data, cluster_assignments, n_clusters)

        # check for convergence
        centroid_change = torch.norm(updated_centroids - centroids)
        if centroid_change < tolerance:
            converged = True
            print(f'Converged after {iteration} iterations')
            break

        centroids = updated_centroids

    if not converged:
        print(f'Failed to converge after {max_iterations} iterations')

# %% ../../02.01_pb_k_means.ipynb 50
def k_means_gpu(data, n_clusters=5, max_iterations=10, tolerance=1e-4, centroids=None):
    converged = False
    data = data.cuda()
    if centroids is not None:
        centroids = centroids.cuda()
    else:
        # Initialize centroids if they were not provided
        centroids = torch.rand(n_clusters, data.shape[-1], device='cuda') * (data.max(dim=0).values - data.min(dim=0).values) + data.min(dim=0).values


        for iteration in range(max_iterations):
            # assign data points to nearest centroid
            cluster_assignments = assign_to_nearest_centroid(data, centroids)
            # update centroids
            updated_centroids = update_centroids(data, cluster_assignments, n_clusters)

            # check for convergence
            centroid_change = torch.norm(updated_centroids - centroids)
            if centroid_change < tolerance:
                converged = True
                print(f'Converged after {iteration} iterations')
                break

            centroids = updated_centroids

    if not converged:
        print(f'Failed to converge after {max_iterations} iterations')
