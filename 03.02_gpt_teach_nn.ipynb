{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp 03.02_app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting Creating Simple Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I progress through Part 2 of the fastai course, I've discovered the value of occasionally retracing my steps to assess my grasp on the fundamental concepts. In my journey through Part 1, I recall Chapter 4 of the book being particularly daunting, as it covered a broad range of essential topics early on. However, this comprehensive approach was necessary to establish a strong foundation for everything I would subsequently learn.\n",
    "\n",
    "Whenever I revisit those earlier chapters and analyze the code line by line, I'm often pleasantly surprised by the level of intuition I've developed in certain areas. Simultaneously, I'm also confronted with aspects that still elude my immediate understanding. Engaging in quick drills to reinforce these concepts has proven to be an effective method for staying sharp and achieving complete comprehension, even if it may feel somewhat repetitive. It's like eating vegetables as a child – you may not want to, but it's ultimately beneficial and necessary for growth. I believe that through a similar positive feedback loop, I will acquire a taste for this process and derive great rewards from it.\n",
    "\n",
    "So, grab a fork and let's dig in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Bank Loan Default from Synthetic Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise I'm going to create synthetic data to predict whether a bank loan will default. I've chosen the following to create as features:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loan Amount \n",
    "- Term \n",
    "- Interest Rate \n",
    "- Borrower's Income \n",
    "- Borrower's Credit Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "torch.set_printoptions(precision=4, linewidth=140, threshold=500, sci_mode=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're first going to create the data for 1000 samples randomly with `torch.normal`, to which we'll pass arguments for a *mean*, *standard deviation*, and *size*.\n",
    "\n",
    "The size could be either a tuple or a list, but for this exercise we'll just use a tuple with a single value.\n",
    "\n",
    "Also worth noting that `term` will be using `randint` rather than `normal`, because loan terms are generally in whole months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "n_samples = 1000\n",
    "loan_amount = torch.normal(5000., 1500, size=(n_samples,))  # average loan amount is $5000\n",
    "term = torch.randint(12, 60, size=(n_samples,))  # loan term varies between 1 and 5 years\n",
    "interest_rate = torch.normal(0.05, 0.01, size=(n_samples,))  # average interest rate is 5%\n",
    "income = torch.normal(50000, 10000, size=(n_samples,))  # average income is $50,000\n",
    "credit_score = torch.normal(600, 50, size=(n_samples,))  # average credit score is 600"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll stack the tensors and create a target variable where 10% of loans default, and convert them to *float32* data types in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "x = torch.column_stack([loan_amount, term, interest_rate, income, credit_score]).float()\n",
    "y = torch.distributions.categorical.Categorical(torch.tensor([0.9, 0.1])).sample((n_samples,)).float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to add a unit axis to our dependent variable so that it can be properly broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done using either `view` or specifying `None` on the axis we want to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "y = y[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, let's move onto the creation of our neural network!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Simple Neural Network with Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we're going to use 2 linear transformation layers, a *ReLU* activation layer with 3 nodes, and a sigmoid activation for the output to get our probability, between 0 and 1. To add a bit of an extra challege for myself I'm going to combine the steps into a class. Classes are something that I haven't had to use much yet, and this seems like a great opportunity to give myself some progressive overload on the mental muscles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.lin_1 = torch.nn.Linear(5, 3)\n",
    "        self.lin_2 = torch.nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin_2(x)\n",
    "        output = F.relu(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "model = SimpleNet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to define a *Loss Function* to evaluate our model with, for simplicity, we'll use a *Mean Squared Error(MSE)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def mse(output, target):\n",
    "    return (output - target).pow(2).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to specify our learning rate, and how we want to optimize our model, which is *Stochastic Gradient Descent(SGD)* in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to put it all in a loop, and run it a few times\n",
    "\n",
    "In the loop we're going to:\n",
    "- Generate predictions with our model\n",
    "- Calculate the loss with our loss function\n",
    "- Compute the gradients with respect to our parameters\n",
    "- Update the parameters using our optimizer\n",
    "- Zero the gradients to prepare for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 968015.5\n",
      "Epoch: 1, Loss: 0.09799999743700027\n",
      "Epoch: 2, Loss: 0.09799999743700027\n",
      "Epoch: 3, Loss: 0.09799999743700027\n",
      "Epoch: 4, Loss: 0.09799999743700027\n",
      "Epoch: 5, Loss: 0.09799999743700027\n",
      "Epoch: 6, Loss: 0.09799999743700027\n",
      "Epoch: 7, Loss: 0.09799999743700027\n",
      "Epoch: 8, Loss: 0.09799999743700027\n",
      "Epoch: 9, Loss: 0.09799999743700027\n",
      "Epoch: 10, Loss: 0.09799999743700027\n",
      "Epoch: 11, Loss: 0.09799999743700027\n",
      "Epoch: 12, Loss: 0.09799999743700027\n",
      "Epoch: 13, Loss: 0.09799999743700027\n",
      "Epoch: 14, Loss: 0.09799999743700027\n",
      "Epoch: 15, Loss: 0.09799999743700027\n",
      "Epoch: 16, Loss: 0.09799999743700027\n",
      "Epoch: 17, Loss: 0.09799999743700027\n",
      "Epoch: 18, Loss: 0.09799999743700027\n",
      "Epoch: 19, Loss: 0.09799999743700027\n",
      "Epoch: 20, Loss: 0.09799999743700027\n",
      "Epoch: 21, Loss: 0.09799999743700027\n",
      "Epoch: 22, Loss: 0.09799999743700027\n",
      "Epoch: 23, Loss: 0.09799999743700027\n",
      "Epoch: 24, Loss: 0.09799999743700027\n",
      "Epoch: 25, Loss: 0.09799999743700027\n",
      "Epoch: 26, Loss: 0.09799999743700027\n",
      "Epoch: 27, Loss: 0.09799999743700027\n",
      "Epoch: 28, Loss: 0.09799999743700027\n",
      "Epoch: 29, Loss: 0.09799999743700027\n",
      "Epoch: 30, Loss: 0.09799999743700027\n",
      "Epoch: 31, Loss: 0.09799999743700027\n",
      "Epoch: 32, Loss: 0.09799999743700027\n",
      "Epoch: 33, Loss: 0.09799999743700027\n",
      "Epoch: 34, Loss: 0.09799999743700027\n",
      "Epoch: 35, Loss: 0.09799999743700027\n",
      "Epoch: 36, Loss: 0.09799999743700027\n",
      "Epoch: 37, Loss: 0.09799999743700027\n",
      "Epoch: 38, Loss: 0.09799999743700027\n",
      "Epoch: 39, Loss: 0.09799999743700027\n",
      "Epoch: 40, Loss: 0.09799999743700027\n",
      "Epoch: 41, Loss: 0.09799999743700027\n",
      "Epoch: 42, Loss: 0.09799999743700027\n",
      "Epoch: 43, Loss: 0.09799999743700027\n",
      "Epoch: 44, Loss: 0.09799999743700027\n",
      "Epoch: 45, Loss: 0.09799999743700027\n",
      "Epoch: 46, Loss: 0.09799999743700027\n",
      "Epoch: 47, Loss: 0.09799999743700027\n",
      "Epoch: 48, Loss: 0.09799999743700027\n",
      "Epoch: 49, Loss: 0.09799999743700027\n",
      "Epoch: 50, Loss: 0.09799999743700027\n",
      "Epoch: 51, Loss: 0.09799999743700027\n",
      "Epoch: 52, Loss: 0.09799999743700027\n",
      "Epoch: 53, Loss: 0.09799999743700027\n",
      "Epoch: 54, Loss: 0.09799999743700027\n",
      "Epoch: 55, Loss: 0.09799999743700027\n",
      "Epoch: 56, Loss: 0.09799999743700027\n",
      "Epoch: 57, Loss: 0.09799999743700027\n",
      "Epoch: 58, Loss: 0.09799999743700027\n",
      "Epoch: 59, Loss: 0.09799999743700027\n",
      "Epoch: 60, Loss: 0.09799999743700027\n",
      "Epoch: 61, Loss: 0.09799999743700027\n",
      "Epoch: 62, Loss: 0.09799999743700027\n",
      "Epoch: 63, Loss: 0.09799999743700027\n",
      "Epoch: 64, Loss: 0.09799999743700027\n",
      "Epoch: 65, Loss: 0.09799999743700027\n",
      "Epoch: 66, Loss: 0.09799999743700027\n",
      "Epoch: 67, Loss: 0.09799999743700027\n",
      "Epoch: 68, Loss: 0.09799999743700027\n",
      "Epoch: 69, Loss: 0.09799999743700027\n",
      "Epoch: 70, Loss: 0.09799999743700027\n",
      "Epoch: 71, Loss: 0.09799999743700027\n",
      "Epoch: 72, Loss: 0.09799999743700027\n",
      "Epoch: 73, Loss: 0.09799999743700027\n",
      "Epoch: 74, Loss: 0.09799999743700027\n",
      "Epoch: 75, Loss: 0.09799999743700027\n",
      "Epoch: 76, Loss: 0.09799999743700027\n",
      "Epoch: 77, Loss: 0.09799999743700027\n",
      "Epoch: 78, Loss: 0.09799999743700027\n",
      "Epoch: 79, Loss: 0.09799999743700027\n",
      "Epoch: 80, Loss: 0.09799999743700027\n",
      "Epoch: 81, Loss: 0.09799999743700027\n",
      "Epoch: 82, Loss: 0.09799999743700027\n",
      "Epoch: 83, Loss: 0.09799999743700027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:00<00:00, 834.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84, Loss: 0.09799999743700027\n",
      "Epoch: 85, Loss: 0.09799999743700027\n",
      "Epoch: 86, Loss: 0.09799999743700027\n",
      "Epoch: 87, Loss: 0.09799999743700027\n",
      "Epoch: 88, Loss: 0.09799999743700027\n",
      "Epoch: 89, Loss: 0.09799999743700027\n",
      "Epoch: 90, Loss: 0.09799999743700027\n",
      "Epoch: 91, Loss: 0.09799999743700027\n",
      "Epoch: 92, Loss: 0.09799999743700027\n",
      "Epoch: 93, Loss: 0.09799999743700027\n",
      "Epoch: 94, Loss: 0.09799999743700027\n",
      "Epoch: 95, Loss: 0.09799999743700027\n",
      "Epoch: 96, Loss: 0.09799999743700027\n",
      "Epoch: 97, Loss: 0.09799999743700027\n",
      "Epoch: 98, Loss: 0.09799999743700027\n",
      "Epoch: 99, Loss: 0.09799999743700027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 807.67it/s]\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    preds = model(x)\n",
    "    loss = mse(preds, y)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss}\", flush=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev\n",
    "nbdev.export.nb_export(\"03.02_gpt_teach_nn.ipynb\", \"03.02_app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
